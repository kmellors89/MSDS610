{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22d26ec-adac-4140-8e53-c7cc32815b6d",
   "metadata": {},
   "source": [
    "# Mellors MSDS610 Week6 Assignment - Notebook 2: Running the Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20398f45-8fb9-4c99-ad3b-4b6ae75a5406",
   "metadata": {},
   "source": [
    "# Loading Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3818adea-1383-49ed-be04-a1da620b5441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bc69de-97ad-44d1-97cc-bb95ffaa69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = joblib.load(\"xgb_model.pkl\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653da89c-4849-4fdd-abd6-cc1a68139183",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_csv(\"X_val.csv\")\n",
    "y_val = pd.read_csv(\"y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e487cbb-940b-42b0-9a38-0b11c63bb062",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 480 entries, 0 to 479\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   combined_text  480 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d640b05-5dab-4aec-bc0e-d15a91c738b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action  comedy  horror monster  pub  duringcre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comedy  drama  mystery independent film every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action  comedy  crime new york  money launderi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comedy hotel  infidelity  onenight stand  frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comedy alcohol  baby  party  family  fraternit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       combined_text\n",
       "0  action  comedy  horror monster  pub  duringcre...\n",
       "1  comedy  drama  mystery independent film every ...\n",
       "2  action  comedy  crime new york  money launderi...\n",
       "3  comedy hotel  infidelity  onenight stand  frie...\n",
       "4  comedy alcohol  baby  party  family  fraternit..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae59120-5f37-40eb-b73b-bd1ccc47f262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 480 entries, 0 to 479\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   worth_funding  480 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 3.9 KB\n"
     ]
    }
   ],
   "source": [
    "y_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc51fca3-046a-4f01-857e-ee691cd52086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worth_funding\n",
       "0                241\n",
       "1                177\n",
       "2                 62\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbff5a-57c6-4566-a6ff-57a73ecd0ee1",
   "metadata": {},
   "source": [
    "# Testing the Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4485704-3049-4831-870a-28c45bc1ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tfidf = vectorizer.transform(X_val[\"combined_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec026d05-4aab-44d2-8fa6-2ea75dbfb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56595294-0f92-4c1d-98fb-18632fb2a347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5292\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.77      0.63       241\n",
      "           1       0.54      0.35      0.42       177\n",
      "           2       0.33      0.11      0.17        62\n",
      "\n",
      "    accuracy                           0.53       480\n",
      "   macro avg       0.47      0.41      0.41       480\n",
      "weighted avg       0.51      0.53      0.50       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b850ce-c41b-45c0-be69-58d7d9ef6779",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b15e6c-0589-4e96-8d88-a7e2b701f5c6",
   "metadata": {},
   "source": [
    "For this assignment, I decided to switch up the model I used. Last week I used an RF model, which performed poorly, and since this is a text-based dataset I decided to try XGBOOST (I also tried SVM and LogisticRegression, but they performed as poorly as the RF model). I liked the results I was getting from XGBoost - I have tuned it and ran it and re-ran it many times - my initial prediction was 98% and I rab my validation and got a 52%. So, I assumed that my model was overfitting. As such, I went back and adjusted the parameters for my XGB, by adjusting the parameters to reduce overfitting (improve generalization), which it did, bringing the accuracy down with it (to the now 72%). And, no matter what I did (including adding SMOTE and parameter tuning), my validation always stayed low. I am not sure if I am missing something, because I feel like my model is able to work well with the training data, or if it is something else. The only real conclusions I can come up with are: This is not a good model type for what I am trying to do, text-based features are not good predicators of film success, or I do not have enough data (my dataset is too small, <5,000 entries). With each parameter tuning to improve generalization, my validation did improve (very, very, very, slightly) to the point that as of submitting, my initial training models is 72% accuracy and my validation has 53% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70745e-f139-4cf8-858f-6858e9238e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
